# -*- coding: utf-8 -*-
"""SBIC_newcodeanalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LJa-39pDBKsG1geYQ-QezO3AtDqfA1wJ
"""

import pandas as pd
import re

def normalize_text(text):
    """
    Normalize text for consistent comparison.
    """
    if not isinstance(text, str):
        return text
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra whitespace
    text = re.sub(r'[^\x00-\x7F]+', '', text)  # Remove non-visible characters
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra whitespace
    text = re.sub(r'^\.\s', '', text)
    return text

# Load the files
input_file = "SBIC.csv"
moderated_file = "sbic_mod.csv"
non_moderated_file = "sbic_notMod.csv"

# Load CSVs into dataframes
input_df = pd.read_csv(input_file)
moderated_df = pd.read_csv(moderated_file)
non_moderated_df = pd.read_csv(non_moderated_file, on_bad_lines="skip", engine="python")

# Define patterns to remove
patterns = ['!dice', '!audit', r'You rolled a [1-6]']

# Create a regex pattern that matches any of the defined patterns
regex_pattern = '|'.join(patterns)
non_moderated_df = non_moderated_df[~non_moderated_df['message'].str.match(regex_pattern, na=False)]

non_moderated_df = non_moderated_df.drop_duplicates(subset='message')
# print(non_moderated_df.head(10))

moderated_df['msg_sent'] = moderated_df['msg_sent'].apply(normalize_text)
input_df['text'] = input_df['text'].apply(normalize_text)
non_moderated_df['message'] = non_moderated_df['message'].apply(normalize_text)

# Preprocessing: Remove duplicates based on 'msg_sent' column in moderated_df and 'message' in non_moderated_df
moderated_df = moderated_df.drop_duplicates(subset='msg_sent')
non_moderated_df = non_moderated_df.drop_duplicates(subset='message')
input_df = input_df.drop_duplicates(subset='text')

print(len(moderated_df))
print(len(non_moderated_df))
print(len(input_df))
input_df = input_df.drop(8849)
non_moderated_df = non_moderated_df.drop(7824)
# Combine data from both files
moderated_texts = moderated_df[['msg_sent']].copy()
moderated_texts['twitch_output'] = 1

non_moderated_texts = non_moderated_df[['message']].copy()
non_moderated_texts.rename(columns={'message': 'msg_sent'}, inplace=True)
non_moderated_texts['twitch_output'] = 0


# Concatenate the two dataframes
combined_df = pd.concat([moderated_texts, non_moderated_texts], ignore_index=True)

unmatched_msg_sent = []

# Process each msg_sent in output_data
for output_text in combined_df['msg_sent']:
    # Check if output_text exists in input_data['text'] exactly
    exact_match = input_df['text'] == output_text

    if exact_match.any():
        # If exact match exists, no changes needed
        continue

    # Check if output_text is a prefix of any input_data['text']
    prefix_match = input_df['text'].apply(lambda x: x.startswith(output_text))

    if prefix_match.any():
        # Truncate the matching input text to match output_text
        input_df.loc[prefix_match, 'text'] = output_text
    else:
        # Track unmatched msg_sent for review
        unmatched_msg_sent.append(output_text)

unmatched_msg_sent_df = pd.DataFrame({'unmatched_msg_sent': unmatched_msg_sent})

len(unmatched_msg_sent), input_df.shape
print(len(unmatched_msg_sent))
unmatched_msg_sent_df.to_csv("unmatched_sbic.csv")
# Total examples
total_examples = len(input_df)

# Examples non-moderated
non_moderated_count = len(combined_df[combined_df['twitch_output'] == 0])

# Examples moderated due to filter
moderated_filter_count = total_examples - non_moderated_count

# Calculate percentages
non_moderated_percent = (non_moderated_count / total_examples) * 100
moderated_percent = (moderated_filter_count / total_examples) * 100

# Display results
print(f"Total examples: {total_examples}")
print(f"Non-moderated examples: {non_moderated_count} ({non_moderated_percent:.2f}%)")
print(f"Total moderated examples: {moderated_filter_count} ({moderated_percent:.2f}%)")

merged_data = input_df.merge(combined_df, left_on='text', right_on='msg_sent', how='left', indicator=True)
print(len(merged_data))

print(input_df.columns)
print(combined_df.columns)
print(merged_data.columns)

# Fill missing label values with 0
merged_data['twitch_output'] = merged_data['twitch_output'].fillna(2).astype(int)
print(merged_data['twitch_output'].value_counts())
merged_data['moderation'] = merged_data['twitch_output'].apply(lambda x: 1 if x in [1, 2] else 0)
    
print(merged_data['moderation'].value_counts())
merged_data.to_csv('sbic_Level1.csv', index=False)

offensiveYN_values = [0, 0.166667, 0.333333, 0.5, 0.666667, 0.75, 0.833333, 1]
output_values = [0, 1]

print("Statistics for offensiveYN thresholds and output distribution:")
for offensive_threshold in offensiveYN_values:
    # Filter data based on offensive threshold
    threshold_df = merged_data[merged_data['offensiveYN'] >= offensive_threshold]
    total_threshold_count = len(threshold_df)

    if total_threshold_count > 0:
        print(f"\nFor offensiveYN >= {offensive_threshold}:")
        for output_value in output_values:
            count = len(threshold_df[threshold_df['moderation'] == output_value])
            percentage = (count / total_threshold_count) * 100
            print(f"  Output == {output_value}: {count} ({percentage:.2f}%)")
    else:
        print(f"\nFor offensiveYN >= {offensive_threshold}: No data available.")

# Special cases for exact thresholds
print("\nSpecial cases:")
count_banned_offensiveness_0 = len(merged_data[(merged_data['offensiveYN'] == 0) & (merged_data['moderation'] == 0)])
count_non_banned_offensiveness_0 = len(merged_data[(merged_data['offensiveYN'] == 0) & (merged_data['moderation'] == 1)])
total_offensiveness_0 = count_banned_offensiveness_0 + count_non_banned_offensiveness_0

if total_offensiveness_0 > 0:
    percentage_banned_offensiveness_0 = (count_banned_offensiveness_0 / total_offensiveness_0) * 100
    percentage_non_banned_offensiveness_0 = (count_non_banned_offensiveness_0 / total_offensiveness_0) * 100
    print(f"  OffensiveYN == 0 -> Output == 0: {count_banned_offensiveness_0} ({percentage_banned_offensiveness_0:.2f}%)")
    print(f"  OffensiveYN == 0 -> Output == 1: {count_non_banned_offensiveness_0} ({percentage_non_banned_offensiveness_0:.2f}%)")

count_banned_offensiveness_1 = len(merged_data[(merged_data['offensiveYN'] == 1) & (merged_data['moderation'] == 0)])
count_non_banned_offensiveness_1 = len(merged_data[(merged_data['offensiveYN'] == 1) & (merged_data['moderation'] == 1)])
total_offensiveness_1 = count_banned_offensiveness_1 + count_non_banned_offensiveness_1

if total_offensiveness_1 > 0:
    percentage_banned_offensiveness_1 = (count_banned_offensiveness_1 / total_offensiveness_1) * 100
    percentage_non_banned_offensiveness_1 = (count_non_banned_offensiveness_1 / total_offensiveness_1) * 100
    print(f"  OffensiveYN == 1 -> Output == 0: {count_banned_offensiveness_1} ({percentage_banned_offensiveness_1:.2f}%)")
    print(f"  OffensiveYN == 1 -> Output == 1: {count_non_banned_offensiveness_1} ({percentage_non_banned_offensiveness_1:.2f}%)")

#for paper, condider threshld 0.5
TN = len(merged_data[(merged_data['offensiveYN'] <1) & (merged_data['moderation'] == 0)])
FP = len(merged_data[(merged_data['offensiveYN'] <1) & (merged_data['moderation'] == 1)])
TP = len(merged_data[(merged_data['offensiveYN'] >=1) & (merged_data['moderation'] == 1)])
FN = len(merged_data[(merged_data['offensiveYN'] >=1) & (merged_data['moderation'] == 0)])

SBIC_Global = merged_data[(merged_data['twitch_output'] ==2) & (merged_data['moderation'] == 1)]
SBIC_Global['text'].to_csv("global_sbic.csv",index=False)
print("True Negative (TN):", TN)
print("False Positive (FP):", FP)
print("True Positive (TP):", TP)
print("False Negative (FN):", FN)

precision = TP / (TP + FP)
recall = TP / (TP + FN)
f1_score = 2 * (precision * recall) / (precision + recall)
accuracy = (TP + TN) / (TP + TN + FP + FN)

print("Precision:", precision)
print("Recall:", recall)
print("F1=score:",f1_score)
print("Accuracy:", accuracy)

# print("hate : ", len(merged_data[(merged_data['offensiveYN'] ==1)]))
# print("nonhate : ", len(merged_data[(merged_data['offensiveYN'] !=1)]))

# print("hate : ", len(merged_data[(merged_data['offensiveYN'] >=0.5)]))
# print("nonhate : ", len(merged_data[(merged_data['offensiveYN'] <0.5)]))

